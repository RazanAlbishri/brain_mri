# -*- coding: utf-8 -*-
"""Brain-FastAPI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WjEpp0SF8IKEO_LYnsdOmPMKOloyKYRH
"""

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import numpy as np
from PIL import Image
import tensorflow as tf
import os
import io
import logging

# Disable GPU (Render free instances do not have CUDA)
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI app
app = FastAPI(
    title="AI Medical Assistant - Brain MRI Classifier",
    description="Upload a brain MRI scan and get AI-based tumor classification",
    version="1.0"
)

# Allow CORS from all origins
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Load the model
MODEL_PATH = 'MRI_brain_Model.h5'
if not os.path.exists(MODEL_PATH):
    logger.error(f"Model file not found at {MODEL_PATH}")
    raise FileNotFoundError(f"Model file not found at {MODEL_PATH}")

model = tf.keras.models.load_model(MODEL_PATH)
class_names = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']

# Arabic translations
translation = {
    'Glioma': 'ورم دبقي (Glioma)',
    'Meningioma': 'ورم سحائي (Meningioma)',
    'No Tumor': 'لا يوجد ورم',
    'Pituitary': 'ورم نخامي (Pituitary)'
}

# Helper: preprocess image
def preprocess_image(image_bytes: bytes) -> np.ndarray:
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        img = img.resize((224, 224))
        img_array = np.array(img, dtype=np.float32) / 255.0
        img_array = np.expand_dims(img_array, axis=0)  # (1, 224, 224, 3)
        return img_array
    except Exception as e:
        logger.error(f"Error in image preprocessing: {e}")
        raise HTTPException(status_code=400, detail="Invalid image file.")

# Prediction endpoint
@app.post("/predict")
async def predict_brain(file: UploadFile = File(...)):
    if file.content_type not in ["image/jpeg", "image/png", "image/jpg"]:
        raise HTTPException(status_code=400, detail="Invalid file type. Only jpg/png allowed.")

    image_bytes = await file.read()
    img_array = preprocess_image(image_bytes)

    try:
        predictions = model.predict(img_array)
        pred_idx = int(np.argmax(predictions))
        predicted_class = class_names[pred_idx]
        confidence = float(np.max(predictions)) * 100
    except Exception as e:
        logger.error(f"Error during model prediction: {e}")
        raise HTTPException(status_code=500, detail="Prediction failed. Please try again.")

    response = {
        "prediction": predicted_class,
        "prediction_ar": translation[predicted_class],
        "confidence": f"{confidence:.2f}%",
        "message": "No tumor detected" if predicted_class == "No Tumor" else f"Signs of {predicted_class} detected. Please consult your doctor.",
        "message_ar": "نتائج مطمئنة لا توجد علامات على وجود ورم" if predicted_class == "No Tumor" else f"تم رصد مؤشرات على وجود {translation[predicted_class]}، يُفضل مراجعة الطبيب المختص لتأكيد التشخيص."
    }

    return JSONResponse(content=response)

# Root endpoint
@app.get("/")
def read_root():
    return {"message": "Welcome to AI Medical Assistant - Brain MRI Classifier"}

# Entry point for Render
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "brain_fastapi:app",  # Make sure your file is named brain_fastapi.py
        host="0.0.0.0",
        port=int(os.environ.get("PORT", 8000)),
        log_level="info"
    )